{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg3d-eylbCHd"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1SctzfeQJDdGN2eMRQhJEoQWWO9rovrWh\" width=\"300\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5eyiHwTZNLN"
      },
      "source": [
        "## What is Pytorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is a python package built by **Facebook AI Research (FAIR)** that provides two high-level features:\n",
        "- Tensor computation (like numpy) with strong GPU acceleration\n",
        "- Deep Neural Networks built on a tape-based autograd (*Automatic Gradient Calculation*) system\n",
        "\n",
        "## Why Pytorch?\n",
        "- **More Pythonic**\n",
        "    - Flexible\n",
        "    - Intuitive and cleaner code\n",
        "    - Easy to learn & debug\n",
        "    - Dynamic Computation Graph (*network behavior can be changed programmatically at runtime*)\n",
        "\n",
        "- **More Neural Networkic**\n",
        "    - Write code as the network works\n",
        "    - forward/backward\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd_43_3QTolP"
      },
      "source": [
        "## Checking PyTorch version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQmfkTfSdl_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2497a9a5-79fb-4dfb-becb-53b2dcaf8858"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnCyI5TsG6l8"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "A **PyTorch Tensor** is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic **n-dimensional array** to be used for arbitrary **numeric computation**.\n",
        "\n",
        "The biggest difference between a numpy array and a PyTorch Tensor is that a **PyTorch Tensor can run on either CPU or GPU**. To run operations on the GPU, **just cast the Tensor to a cuda datatype**.\n",
        "\n",
        "\n",
        "A scalar is **zero-order tensor** or rank zero tensor. A vector is a **one-dimensional** or first order tensor, and a matrix is a **two-dimensional** or second order tensor.\n",
        "\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1pka-LVyrq_7r0sCm59cvOQofEYAcnO4r\" width=\"550\">\n",
        "</div>\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1zHT5CGzIgpe1aLkdawrllTMn74nYVeAp\" width=\"550\">\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5blQSOs56dFu"
      },
      "source": [
        "A [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) is a **multi-dimensional matrix** containing elements of a **single data type**.\n",
        "\n",
        "`torch.Tensor` is an alias for the default tensor type (`torch.FloatTensor`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJECsFOO_nVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "baaa9a94-ef80-4377-ce4c-e116ccf2dce3"
      },
      "source": [
        "torch.tensor([[1., -1.], [1., -1.]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1., -1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkYo6MU5GEE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "188caf05-9a3c-4dc5-c7f7-d815293ec91b"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9827, 0.6272, 0.9839],\n",
            "        [0.3059, 0.6539, 0.4298],\n",
            "        [0.1513, 0.3223, 0.4269],\n",
            "        [0.8147, 0.7093, 0.9322],\n",
            "        [0.6179, 0.9020, 0.0030]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5GntwAR_tdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "096b5da3-70c3-44d0-9622-4b4728092f6f"
      },
      "source": [
        "# Converting numpy arrays to tensors\n",
        "import numpy as np\n",
        "torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6K1HB1DuPc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a9e78f6c-f81d-409d-f46d-026a68a022a8"
      },
      "source": [
        "# Converting numpy arrays to tensors\n",
        "np_values = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "tensor_values = torch.from_numpy(np_values)\n",
        "\n",
        "print (tensor_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9zOrpNc_-yT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e69ce034-6f7f-434f-9091-32f06b0a252a"
      },
      "source": [
        "# A tensor of specific data type can be constructed by passing a torch.dtype\n",
        "\n",
        "torch.zeros([2, 4], dtype=torch.int32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0],\n",
              "        [0, 0, 0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsIc2tbfD2um",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fe1da723-e966-4eb2-c4f5-663cd341835a"
      },
      "source": [
        "# The contents of a tensor can be accessed and modified using Python’s indexing and slicing notation:\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x[1][2])\n",
        "\n",
        "# Modify a certain element\n",
        "x[0][1] = 8\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n",
            "tensor([[1, 8, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixEKku4bEerW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1373dfaf-4628-491c-ab29-bb4f3bc20e44"
      },
      "source": [
        "# Use torch.Tensor.item() to get a Python number from a tensor containing a single value\n",
        "\n",
        "x = torch.tensor([[1]])\n",
        "print (x)\n",
        "\n",
        "print(x.item())\n",
        "\n",
        "x = torch.tensor(2.5)\n",
        "\n",
        "print(x.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1]])\n",
            "1\n",
            "2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIqHBWSZEqXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28819a98-bbc8-4995-8dd9-20c22c73f4b6"
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf5LMRZgORa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "bef05dff-7766-4e8e-a1a5-179717eadb1d"
      },
      "source": [
        "# Tensor addition & subtraction\n",
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "print(x + y)\n",
        "print(x - y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3006, 0.7646, 0.5699],\n",
            "        [0.8115, 0.7876, 0.3602],\n",
            "        [0.1724, 0.3275, 0.0543],\n",
            "        [0.1840, 0.0529, 0.7849],\n",
            "        [0.8471, 0.1306, 0.6419]])\n",
            "tensor([[0.0678, 0.3605, 0.4748],\n",
            "        [0.4979, 0.9121, 0.1280],\n",
            "        [0.6105, 0.7482, 0.8507],\n",
            "        [0.0198, 0.8611, 0.7846],\n",
            "        [0.3896, 0.1397, 0.8953]])\n",
            "tensor([[0.3684, 1.1252, 1.0447],\n",
            "        [1.3094, 1.6997, 0.4882],\n",
            "        [0.7830, 1.0757, 0.9049],\n",
            "        [0.2038, 0.9140, 1.5694],\n",
            "        [1.2367, 0.2703, 1.5372]])\n",
            "tensor([[ 2.3281e-01,  4.0406e-01,  9.5038e-02],\n",
            "        [ 3.1355e-01, -1.2456e-01,  2.3215e-01],\n",
            "        [-4.3807e-01, -4.2075e-01, -7.9637e-01],\n",
            "        [ 1.6420e-01, -8.0820e-01,  2.6971e-04],\n",
            "        [ 4.5753e-01, -9.0982e-03, -2.5342e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEo36NgVOhNc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c5761f7f-2ebe-415d-8c57-a9dc4bcbbe42"
      },
      "source": [
        "# Syntax 2 for Tensor addition & subtraction in PyTorch\n",
        "print(torch.add(x, y))\n",
        "print(torch.sub(x, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3684, 1.1252, 1.0447],\n",
            "        [1.3094, 1.6997, 0.4882],\n",
            "        [0.7830, 1.0757, 0.9049],\n",
            "        [0.2038, 0.9140, 1.5694],\n",
            "        [1.2367, 0.2703, 1.5372]])\n",
            "tensor([[ 2.3281e-01,  4.0406e-01,  9.5038e-02],\n",
            "        [ 3.1355e-01, -1.2456e-01,  2.3215e-01],\n",
            "        [-4.3807e-01, -4.2075e-01, -7.9637e-01],\n",
            "        [ 1.6420e-01, -8.0820e-01,  2.6971e-04],\n",
            "        [ 4.5753e-01, -9.0982e-03, -2.5342e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGopWgyCO9eB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "1f3bfb85-d2bd-4397-987c-ed9622d78bb0"
      },
      "source": [
        "# Tensor Product & Transpose\n",
        "\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "\n",
        "print(mat1)\n",
        "print(mat2)\n",
        "\n",
        "print(torch.mm(mat1, mat2))\n",
        "\n",
        "print(mat1.t())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5743, -1.4231,  2.0308],\n",
            "        [-0.8048,  0.6091,  0.6772]])\n",
            "tensor([[-0.3789,  1.0735, -0.1960],\n",
            "        [-0.4697, -0.3032,  0.1264],\n",
            "        [ 0.5271,  0.5391,  1.0751]])\n",
            "tensor([[ 1.5213,  2.1428,  1.8909],\n",
            "        [ 0.3759, -0.6835,  0.9628]])\n",
            "tensor([[ 0.5743, -0.8048],\n",
            "        [-1.4231,  0.6091],\n",
            "        [ 2.0308,  0.6772]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNNdLxAiS6iq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6eec12b-a3a9-4977-81f1-56a0add71d45"
      },
      "source": [
        "# Elementwise multiplication\n",
        "t = torch.Tensor([[1, 2], [3, 4]])\n",
        "t.mul(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  4.],\n",
              "        [ 9., 16.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ien5Sa-sR4Po",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c54d5b4e-f5e6-48ba-ffe3-2b3964bdf38b"
      },
      "source": [
        "# Shape, dimensions, and datatype of a tensor object\n",
        "\n",
        "x = torch.rand(5, 3)\n",
        "\n",
        "print('Tensor shape:', x.shape)   # t.size() gives the same\n",
        "print('Number of dimensions:', x.dim())\n",
        "print('Tensor type:', x.type())   # there are other types"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor shape: torch.Size([5, 3])\n",
            "Number of dimensions: 2\n",
            "Tensor type: torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRbhDxnSbFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e97ddb81-82ce-41b5-f280-f4920f70c231"
      },
      "source": [
        "# Slicing\n",
        "t = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Every row, only the last column\n",
        "print(t[:, -1])\n",
        "\n",
        "# First 2 rows, all columns\n",
        "print(t[:2, :])\n",
        "\n",
        "# Lower right most corner\n",
        "print(t[-1:, -1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 6., 9.])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[9.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWvHVdN_W2tK"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "### PyTorch Model Designing Steps\n",
        "\n",
        "1.   **Design your model using class with Variables**\n",
        "2.   **Construct loss and optimizer  (select from PyTorch API)**\n",
        "3.   **Training cycle (forward, backward, update)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyV1hfzhZ4EB"
      },
      "source": [
        "### Step #1 : Design your model using class with Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWyCJFyUW2TQ"
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch import tensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_data = tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]])\n",
        "y_data = tensor([[2.0], [4.0], [6.0], [8.0], [10.0], [12.0]])\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "num_epochs = 50\n",
        "learning_rate = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM_epadwrutJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4af34a90-c256-4678-a17d-54a8e65242af"
      },
      "source": [
        "print(torch.__version__)\n",
        "\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UTgtmxyqJ1N"
      },
      "source": [
        "### Using GPU for the PyTorch Models\n",
        "\n",
        "Remember always 2 things must be on GPU\n",
        "\n",
        "- model\n",
        "- tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6VTdaeqZ_fo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a637cae9-63c9-487a-af8d-b2a4819591a6"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate nn.Linear module\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)  # One in and one out\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        y_pred = self.linear(x)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# our model\n",
        "model = Model()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQ4YlNxnY4m"
      },
      "source": [
        "### Explanations:-\n",
        "\n",
        "`torch.nn.Linear(in_features, out_features, bias=True)`\n",
        "\n",
        "Applies a linear transformation to the incoming data: $y = W^T * x + b$\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "- `in_features `– size of each input sample (i.e. size of x)\n",
        "- `out_features` – size of each output sample (i.e. size of y)\n",
        "- `bias` – If set to False, the layer will not learn an additive bias. **Default: True**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B67aGn6kaDAh"
      },
      "source": [
        "###Step #2 : Construct loss and optimizer (select from PyTorch API)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj6oN5_daEUI"
      },
      "source": [
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BumRaPT2eApz"
      },
      "source": [
        "### Explanations:-\n",
        "\n",
        "MSE Loss: Mean Squared Error (Default: 'mean')\n",
        "\n",
        "- $\\hat y$ :  prediction\n",
        "- $y$ :  true value\n",
        "\n",
        "$MSE \\ (sum) =  \\sum_{i=1}^n(\\hat y_i - y_i)^2$\n",
        "\n",
        "$MSE \\ (mean) = \\frac{1}{n} \\sum_{i=1}^n(\\hat y_i - y_i)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4ZfKK1uEOl"
      },
      "source": [
        "###Step #3 : Training: forward, loss, backward, step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVZw04-2uGE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "5c3d0db7-0867-4040-9c90-6f4362f70fd8"
      },
      "source": [
        "# Credit: https://github.com/jcjohnson/pytorch-examples\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # 1) Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data.to(device))\n",
        "\n",
        "    # 2) Compute and print loss\n",
        "    loss = criterion(y_pred, y_data.to(device))\n",
        "    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "# After training\n",
        "hour_var = tensor([[7.0]]).to(device)\n",
        "y_pred = model(hour_var)\n",
        "print(\"Prediction (after training)\",  7, model(hour_var).data[0][0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.4046969413757324 \n",
            "Epoch: 1 | Loss: 0.3751128613948822 \n",
            "Epoch: 2 | Loss: 0.34870368242263794 \n",
            "Epoch: 3 | Loss: 0.32503488659858704 \n",
            "Epoch: 4 | Loss: 0.30373701453208923 \n",
            "Epoch: 5 | Loss: 0.28449591994285583 \n",
            "Epoch: 6 | Loss: 0.2670438885688782 \n",
            "Epoch: 7 | Loss: 0.2511536478996277 \n",
            "Epoch: 8 | Loss: 0.23663079738616943 \n",
            "Epoch: 9 | Loss: 0.22330956161022186 \n",
            "Epoch: 10 | Loss: 0.2110479176044464 \n",
            "Epoch: 11 | Loss: 0.1997237652540207 \n",
            "Epoch: 12 | Loss: 0.1892329305410385 \n",
            "Epoch: 13 | Loss: 0.17948590219020844 \n",
            "Epoch: 14 | Loss: 0.17040419578552246 \n",
            "Epoch: 15 | Loss: 0.1619214415550232 \n",
            "Epoch: 16 | Loss: 0.15397928655147552 \n",
            "Epoch: 17 | Loss: 0.1465272456407547 \n",
            "Epoch: 18 | Loss: 0.13952045142650604 \n",
            "Epoch: 19 | Loss: 0.1329210102558136 \n",
            "Epoch: 20 | Loss: 0.12669487297534943 \n",
            "Epoch: 21 | Loss: 0.12081220746040344 \n",
            "Epoch: 22 | Loss: 0.11524614691734314 \n",
            "Epoch: 23 | Loss: 0.1099737286567688 \n",
            "Epoch: 24 | Loss: 0.10497380048036575 \n",
            "Epoch: 25 | Loss: 0.10022743046283722 \n",
            "Epoch: 26 | Loss: 0.09571778774261475 \n",
            "Epoch: 27 | Loss: 0.0914301723241806 \n",
            "Epoch: 28 | Loss: 0.08735045045614243 \n",
            "Epoch: 29 | Loss: 0.08346641808748245 \n",
            "Epoch: 30 | Loss: 0.079766184091568 \n",
            "Epoch: 31 | Loss: 0.07623954117298126 \n",
            "Epoch: 32 | Loss: 0.07287701219320297 \n",
            "Epoch: 33 | Loss: 0.06966972351074219 \n",
            "Epoch: 34 | Loss: 0.06660932302474976 \n",
            "Epoch: 35 | Loss: 0.0636879950761795 \n",
            "Epoch: 36 | Loss: 0.060898974537849426 \n",
            "Epoch: 37 | Loss: 0.05823547765612602 \n",
            "Epoch: 38 | Loss: 0.05569145083427429 \n",
            "Epoch: 39 | Loss: 0.053260963410139084 \n",
            "Epoch: 40 | Loss: 0.05093876272439957 \n",
            "Epoch: 41 | Loss: 0.04871952161192894 \n",
            "Epoch: 42 | Loss: 0.04659825190901756 \n",
            "Epoch: 43 | Loss: 0.044570740312337875 \n",
            "Epoch: 44 | Loss: 0.04263252019882202 \n",
            "Epoch: 45 | Loss: 0.04077941179275513 \n",
            "Epoch: 46 | Loss: 0.039007507264614105 \n",
            "Epoch: 47 | Loss: 0.0373133048415184 \n",
            "Epoch: 48 | Loss: 0.035693153738975525 \n",
            "Epoch: 49 | Loss: 0.034143973141908646 \n",
            "Prediction (after training) 7 13.88995361328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQDkpcGf5C5e"
      },
      "source": [
        "### Explanations:-\n",
        "\n",
        "- Calling `.backward()` mutiple times accumulates the gradient (**by addition**) for each parameter.\n",
        "\n",
        "- This is why you should call `optimizer.zero_grad()` after each .step() call.\n",
        "\n",
        "- Note that following the first `.backward` call, a second call is only possible after you have performed another **forward pass**.\n",
        "\n",
        "- `optimizer.step` performs a parameter update based on the current gradient (**stored in .grad attribute of a parameter**)\n",
        "\n",
        "### Simplified equation:-\n",
        "\n",
        "- `parameters = parameters - learning_rate * parameters_gradients`\n",
        "- parameters $W$ and $b$ in ($y = W^T * x + b$)\n",
        "- $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$  [ General parameter $\\theta$ ]\n",
        "  *  $\\theta$ : parameters (our variables)\n",
        "  *  $\\eta$ : learning rate (how fast we want to learn)\n",
        "  *  $\\nabla_\\theta$ : parameters' gradients\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIjs2MBepwHQ"
      },
      "source": [
        "### Plot of predicted and actual values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JB0tYXsnhy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b9fb12ac-0de6-4bfa-b1da-2fd7a9a33567"
      },
      "source": [
        "# Clear figure\n",
        "plt.clf()\n",
        "\n",
        "# Get predictions\n",
        "predictions = model(x_data.to(device)).cpu().detach().numpy()\n",
        "\n",
        "# Plot true data\n",
        "plt.plot(x_data, y_data, 'go', label='True data', alpha=0.5)\n",
        "\n",
        "# Plot predictions\n",
        "plt.plot(x_data, predictions, '--', label='Predictions', alpha=0.5)\n",
        "\n",
        "# Legend and plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_nJUj7jBFV-"
      },
      "source": [
        "### Saving Model to Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BB9gRPmM624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d88a659f-d654-435c-afe9-6715fdfe2a9f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_path = '/content/gdrive/My Drive/AUST Teaching Docs/AUST Fall 2019/Soft Computing/CSE 4238/Codes/04/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5YnXE3tN9cu"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiOsiWYyBETG"
      },
      "source": [
        "save_model = True\n",
        "\n",
        "if save_model is True:\n",
        "    # Saves only parameters\n",
        "    # wights & biases\n",
        "    torch.save(model.state_dict(), root_path + 'linear_regression.pkl')\n",
        "\n",
        "# Save the model checkpoint\n",
        "# torch.save(model.state_dict(), root_path + 'linear_regression.ckpt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhBapRsyN_Vo"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_n7589AOGwS"
      },
      "source": [
        "load_model = True\n",
        "\n",
        "if load_model is True:\n",
        "    model.load_state_dict(torch.load(root_path + 'linear_regression.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf8fGQJ9Df05"
      },
      "source": [
        "### Try Other Optimizers\n",
        "\n",
        "- torch.optim.Adagrad\n",
        "- torch.optim.Adam\n",
        "- torch.optim.Adamax\n",
        "- torch.optim.ASGD\n",
        "- torch.optim.LBFGS\n",
        "- torch.optim.RMSprop\n",
        "- torch.optim.Rprop\n",
        "- torch.optim.SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI9xGl0Eog09"
      },
      "source": [
        "### *** Official PyTorch Tutorials ***\n",
        "\n",
        "https://pytorch.org/tutorials/"
      ]
    }
  ]
}